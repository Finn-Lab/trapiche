# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/04_cli.ipynb.

# %% auto 0
__all__ = ['biome_herarchy_dct_rev', 'read_taxo_file_list', 'evidence_flag', 'main']

# %% ../nbs/04_cli.ipynb 2
from nbdev.showdoc import *
from fastcore.basics import *
from fastcore.script import *

# %% ../nbs/04_cli.ipynb 3
import logging
import sys
import json
import gzip
import os
import pandas as pd
import numpy as np
import logging
from tqdm import tqdm
import networkx as nx

from .utils import parse_diamond,parse_otus_count,sanity_check_diamond_annot_file,sanity_check_otus_annot_file
from .taxonomyTree import get_subgraph
from .biome2vec import get_terminals, sentence_vectorization
from .knn_communities import find_knn,core_vectors,core_df
from .goldOntologyAmendments import biome_herarchy_dct
from . import bayes_classifier

# %% ../nbs/04_cli.ipynb 4
def read_taxo_file_list(
    files:str # a file with paths to taxonoy annotation files
):
    """ iterate the list of paths, identify the type by the extention, and return a list of tuples of those that passed the sanity check"""
    _result_df = []
    with open(files) as h:
        for file in tqdm(h):
            file = file.strip()
            if 'gz'  == file.split('.')[-1]: # diamond annotation identifier
                content = sanity_check_diamond_annot_file(file)
                if content ==False:
                    mix={}
                else:
                    mix = parse_diamond(content)
                
            # elif 'txt' == file.split('.')[-1]: # diamond annotation identifier
            else: # OTUS annotation identifier
                content = sanity_check_otus_annot_file(file)
                if content ==False:
                    mix={}
                else:
                    mix = parse_otus_count(content)
            _result_df.append((os.path.basename(file),mix))

    return _result_df

        

# %% ../nbs/04_cli.ipynb 5
def evidence_flag(
    row  # pandas row
):
    " assing a color (stop light system) for each biome prediction besed on the amount of evidence "
    
    su = 0
    if row['bayes_classification'] in row['biome_annotation'] or row['biome_annotation'] in row['bayes_classification']:
        su +=4
    if 'knn_classification' in row:
        if row['bayes_classification'] in row['knn_classification'] or row['knn_classification'] in row['bayes_classification']:
            su +=2
        if row['knn_classification'] in row['biome_annotation'] or row['biome_annotation'] in row['knn_classification']:
            su +=1
    return su

# %% ../nbs/04_cli.ipynb 6
biome_herarchy_dct_rev = {v:k for k,v in biome_herarchy_dct.items()}  # dictionary to map amended gold ontology to canonical

# %% ../nbs/04_cli.ipynb 7
@call_parse
def main(
    taxo_files:str,  # text file with paths to files with taxonomic annotations from MGnify. It can be in OTU counts (tsv extention) or diamond annotation (tsv.gz extention)
    get_embeddings="biome_embeddings.json",  # write embeddings in json file {biome_1:embedding,biome_2:embedding,...}
    annots_file=None,  # text file with the same number of lines as `taxo_files` corresponding to the (biome) annotation in the DB. This will aid the flag system
    knn=bool,  # run knn classification 
    output_file='trapiche.out.txt',  # output file in which results will be saved. Default 'trapiche.'
    mc=50,  # number of Monte Carlo dropout predictions
    cl=0.95,  # confidence level for rejection function
    thres=0.5,  # prediction probability threshold
    fill=True,  # fill gaps in prediction Tree
    subject_vectors=None, # reference vectors for knn classification. npy format. This should change as new data is incorporated
    subject_df=None, # reference dataframe for knn classification. tsv format. This should change as new data is incorporated, and data is curated. see knn_communities notebook for reference
    log_file='sanntis.log' # log file name
):
    """
    Main function of CLI
    """
    # Set up logging
    logging.basicConfig(level=logging.INFO,
                        format="%(asctime)s [%(levelname)s] %(message)s",
                        filename=log_file,
                        filemode='a'
                       )
    logger = logging.getLogger(__name__)
    
    
    logger.info("Starting Trapiche processing...")
    
    if subject_vectors!= None:
        _core_vectors = np.load(subject_vectors)
        logger.info("load reference vectors...")
    else:
        _core_vectors = np.array(core_vectors)
    if subject_df!= None:
        _core_df = pd.read_csv(subject_df,sep='\t')
        logger.info("load reference dataframe...")
    else:
        _core_df = pd.DataFrame(core_df)
    
    logger.info("files sanity check and vectorization...")
    _df_result = read_taxo_file_list(taxo_files)
    df_result = pd.DataFrame(_df_result,columns = 'file mix'.split())
    logger.info("assign annotation column...")
    if annots_file==None:
        logger.info("No annotation provided. Flag system turned off...")
        df_result['biome_annotation'] = ['None' for _ in range(df_result.shape[0])]
    else:
        with open(annots_file) as h:
            df_result['biome annotation'] = [x.strip() for x in h]
        
    logger.info("calculate subgraph for each taxonomic annotation file...")
    df_result['subgraph'] = df_result.mix.map( lambda x:list(nx.to_edgelist(get_subgraph(x))) ) # find the subgraph in trapiche taxonomy tree

    logger.info("get leaf nodes...")
    df_result['terminals'] = df_result.subgraph.map( get_terminals ) # 
    
    logger.info("calculate sample embedding (vectors)...")
    df_result['vectors'] = df_result.terminals.map( sentence_vectorization ) # 
    
    logger.info("check samples with no meaningful taxa...")
    no_vector_mask = [ix for ix,x in df_result.vectors.items() if type(x)==np.float64]
    zeros_array = np.zeros(200)
    for index in no_vector_mask:
        logger.info(f"the sample {df_result.loc[index].file} has no meaningful taxa")
        df_result.at[index, 'vectors'] = zeros_array
        
    logger.info(f"found {len(no_vector_mask)} samples with no meaningful taxa")
    
    if get_embeddings!= None:
        logger.info("Only return embedding file")
        
        keep = ['file','vectors']
        logger.info("saving results...")
        vectors_json = {f:[float(x) for x in v] if ix not in no_vector_mask else None for ix,(f,v) in enumerate(df_result[keep].values)}
        with open(get_embeddings,"w") as h:
            json.dump(vectors_json,h)
            
        
    
    if knn ==True:
        logger.info("knn classification...")
        # df_result['knn_classification'] = df_result.vectors.map( lambda x: find_knn(x,_core_vectors,_core_df)[0] ) # 
        df_result['knn_classification_gold_amended'] = [find_knn(x,_core_vectors,_core_df)[0] for x in tqdm(df_result.vectors)]  # results in amended GOLD ontology
        df_result['knn_classification'] = df_result.knn_classification_gold_amended.map(lambda x:biome_herarchy_dct_rev.get(x,x)) # map results to GOLD ontology
        
    # return df_result
    logger.info("bayes classification...")
    colapsed_pred,mc_mean,lower_bounds,upper_bounds,path_prob = bayes_classifier.find_most_prob(np.array([x for x in df_result.vectors]),T=mc,confidence_level=cl,thres=thres,fill=fill)
    #colapsed_pred, _mc_mean, _lower_bounds, _upper_bounds, path_p
    df_result['bayes_classification_gold_amended'] = colapsed_pred # results in amended GOLD ontology
    df_result['bayes_classification'] = df_result.bayes_classification_gold_amended.map(lambda x:biome_herarchy_dct_rev.get(x,x)) # map results to GOLD ontology
    df_result['probability'] = mc_mean
    df_result['confidence_lower_bounds'] = lower_bounds
    df_result['confidence_upper_bounds'] = upper_bounds
    df_result['path_prob'] = path_prob
    
        
    
    if annots_file != None:
        logger.info("flag system...")
        df_result['flag'] = df_result.apply(evidence_flag,axis=1)
    
    keep = 'file bayes_classification bayes_classification_gold_amended probability confidence_lower_bounds confidence_upper_bounds path_prob {} {} {}'.format(
        'knn_classification knn_classification_gold_amended' if knn==True else '',
        'biome_annotation' if annots_file!=None else '',
        'flag' if annots_file!=None else '',
    ).split() 
    
    logger.info("clean no meaninful results...")
    df_result.loc[no_vector_mask,['bayes_classification']] = 'Unknown'
    df_result.loc[no_vector_mask,['bayes_classification_gold_amended']] = 'Unknown'
    
    logger.info("saving results...")
    df_result[keep].to_csv(output_file,sep='\t',index=False)
    
    logger.info("DONE")

