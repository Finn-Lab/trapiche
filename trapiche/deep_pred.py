# Copyright 2024 EMBL - European Bioinformatics Institute
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific la

# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/01.2_deep_pred.ipynb.

# %% auto 0
__all__ = ['TAG', 'DATA_DIR', 'TMP_DIR', 'vec_size', 'min_annots', 'k', 'min_projects_vote', 'dominance_thres', 'k2',
           'dominance_thres2', 'core_df_file', 'genus_plus_sp_vec_file', 'genus_vec_file', 'core_df', 'genus_vec',
           'genus_plus_sp_vec', 'tags_dct_file', 'tags_li', 'bioms', 'tag_biomes', 'tnp_core_df_file', 'slim_core_df',
           'final_model_file', 'bnn_model2gg', 'get_species_from_diamond_set',
           'process_get_average_embedd_macro_average_by_genus', 'process_diamond', 'process_krona', 'extract_taxo',
           'calculate_mean_gr_vec', 'calculate_gr_macro_vec', 'calculate_gr_plus_sp_vec', 'load_core_data',
           'generate_all_combinations', 'pc_deviation_consensus', 'focal_loss_fixed', 'find_best_path',
           'from_probs_to_pred', 'get_lineage_frquencies', 'refine_predictions_knn', 'full_stack_prediction',
           'chunked_fuzzy_prediction', 'vectorise_run', 'predict_runs']

# %% ../nbs/01.2_deep_pred.ipynb 4
import glob
import os
import json
import re
import pandas as pd
import math
import numpy as np
from tqdm import tqdm
from ssfMiscUtilities.generic import *
import tensorflow as tf

from . import config

# %% ../nbs/01.2_deep_pred.ipynb 5
from .goldOntologyAmendments import gold_categories,biome_graph,biome_original_graph

# %% ../nbs/01.2_deep_pred.ipynb 7
TAG = 'deep_pred'

# %% ../nbs/01.2_deep_pred.ipynb 8
DATA_DIR = f"{config.basedir}/data/{TAG}"

# %% ../nbs/01.2_deep_pred.ipynb 9
os.makedirs(DATA_DIR,exist_ok=True)

# %% ../nbs/01.2_deep_pred.ipynb 10
TMP_DIR = f"{DATA_DIR}/temp"

# %% ../nbs/01.2_deep_pred.ipynb 12
from . import taxonomyTree
from .baseData import analysis_df
from .baseData import load_taxonomy_sets
from .baseData import RESULTS_BASE_DIR

# %% ../nbs/01.2_deep_pred.ipynb 13
from .utils import cosine_similarity,jaccard_similarity,cosine_similarity_pairwise

# %% ../nbs/01.2_deep_pred.ipynb 16
from .biome2vec import taxo_ids
from .taxonomyTree import taxonomy_graph
from .biome2vec import sentence_vectorization
# from trapiche.baseData import load_taxonomy_sets

# %% ../nbs/01.2_deep_pred.ipynb 20
def get_species_from_diamond_set(taxo_set):
    """ function to extract the tax_annot as sp level in diamond
    """
    resu =  set()
    for x in taxo_set:
        spl = x.split()
        if len(spl)<2:continue
        resu.update({" ".join(x.split()[:2])})
    return resu

def process_get_average_embedd_macro_average_by_genus(set_of_species):
    """ function to calculate macro average vector at sp level, weighted by genus
    return dictionary with {genus:vector_of_sp_at_genus}
    """
    dct,mat = {},{}
    for i in set_of_species:
        dct.setdefault(i.split()[0],[]).append(i)
    
    for g,s in dct.items():
        cu = sentence_vectorization(s)
        mat[g] = cu
    return mat

def process_diamond(taxo_set):
    """ function to extract species and genus from diamon taxonomic annot
    """
    sp = get_species_from_diamond_set(taxo_set)
    gr = {x.split()[0] for x in sp}
    return sp,gr


# %% ../nbs/01.2_deep_pred.ipynb 21
def process_krona(taxo_set):
    """ function to extract species and genus from SSU/LLU taxonomic annot
    """
    sp = {" ".join(x.split('__')[-1].replace('_',' ').split()[:2]).replace('_',' ') for x in taxo_set if len( x.split('__')[-1].replace('_',' ').split() )>1}
    gr = {x.split('__')[-1] for x in taxo_set if 'g' == x.split('__')[0]}
    return sp,gr


# %% ../nbs/01.2_deep_pred.ipynb 22
def extract_taxo(taxo_set,file):
    """Wrapper to extract taxo from diamond or krona given a set of taxonomic annotations
    """
    if 'diamond' in file:
        sp,gr = process_diamond(taxo_set)
    else:
        sp,gr = process_krona(taxo_set)
    return sp,gr

# %% ../nbs/01.2_deep_pred.ipynb 27
def calculate_mean_gr_vec(p,gr):
    """ fuinction to calculate the mean of a set of gr
    """
    vec = sentence_vectorization(gr)
    return vec
    
def calculate_gr_macro_vec(sp,gr):
    """ fuinction to calculate the mean of a set . genus macro av
    """
    sp_mat = process_get_average_embedd_macro_average_by_genus(sp)
    
    mis_gr = gr-set(sp_mat)
    mean2 = sentence_vectorization(mis_gr)

    try:
        mean1 = np.mean(np.vstack([x for x in sp_mat.values() if x.dtype=='float32']),axis=0)
    except:
        mean1=mean2

    n1 = len(sp_mat)
    n2 = len(mis_gr)

    if n1+n2==0:
        return float('nan')
    
    sp_mean = (n1 / (n1 + n2)) * mean1 + (n2 / (n1 + n2)) * mean2

    return sp_mean
    
def calculate_gr_plus_sp_vec(sp,gr):
    """ fuinction to calculate the mean of a set of gr_sp stack
    """
    # sp_mat = process_get_average_embedd_macro_average_by_genus(sp)
    mean_sp =calculate_gr_macro_vec(sp,gr)
    mean_gr = sentence_vectorization(gr)
    
    # try:
        # mean_sp = np.mean(np.vstack([x for x in sp_mat.values() if x.dtype=='float32']),axis=0)
    # except:
        # mean_sp=mean_gr
    mean = np.hstack([mean_sp,mean_gr])
    
    return mean


# %% ../nbs/01.2_deep_pred.ipynb 28
vec_size = sentence_vectorization(['root']).shape[0]

# %% ../nbs/01.2_deep_pred.ipynb 32
# list(biome_original_graph.nodes)
# list of biomes that make biological sense

min_annots = {
    'root:Engineered:Biogas plant',
    'root:Engineered:Bioreactor',
    'root:Engineered:Food production',
    'root:Engineered:Solid waste',
    'root:Engineered:Wastewater',
    'root:Environmental:Air',
    'root:Host-associated:Algae',
    'root:Host-associated:Cnidaria',
    'root:Host-associated:Echinodermata',
    'root:Host-associated:Fungi',
    'root:Host-associated:Porifera',
    'root:Environmental:Aquatic:Aquaculture',
    'root:Environmental:Aquatic:Estuary',
    'root:Environmental:Aquatic:Freshwater',
    'root:Environmental:Aquatic:Lentic',
    'root:Environmental:Aquatic:Marine',
    'root:Environmental:Aquatic:Meromictic lake',
    'root:Environmental:Aquatic:Non-marine Saline and Alkaline',
    'root:Environmental:Aquatic:Sediment',
    'root:Environmental:Aquatic:Thermal springs',
    'root:Environmental:Terrestrial:Agricultural field',
    'root:Environmental:Terrestrial:Asphalt lakes',
    'root:Environmental:Terrestrial:Deep subsurface',
    'root:Environmental:Terrestrial:Geologic',
    'root:Environmental:Terrestrial:Oil reservoir',
    'root:Environmental:Terrestrial:Rock-dwelling (subaerial biofilm)',
    'root:Environmental:Terrestrial:Soil',
    'root:Environmental:Terrestrial:Volcanic',
    'root:Host-associated:Amphibia:Digestive system',
    'root:Host-associated:Amphibia:Excretory system',
    'root:Host-associated:Animal:Circulatory system',
    'root:Host-associated:Animal:Digestive system',
    'root:Host-associated:Animal:Fossil',
    'root:Host-associated:Animal:Reproductive system',
    'root:Host-associated:Animal:Respiratory system',
    'root:Host-associated:Animal:Skin',
    'root:Host-associated:Annelida:Digestive system',
    'root:Host-associated:Annelida:Integument',
    'root:Host-associated:Annelida:Intracellular endosymbionts',
    'root:Host-associated:Annelida:Reproductive system',
    'root:Host-associated:Arthropoda:Digestive system',
    'root:Host-associated:Arthropoda:Integument',
    'root:Host-associated:Arthropoda:Intracellular endosymbionts',
    'root:Host-associated:Arthropoda:Oral cavity',
    'root:Host-associated:Arthropoda:Respiratory system',
    'root:Host-associated:Arthropoda:Symbiotic fungal gardens and galleries',
    'root:Host-associated:Arthropoda:Venom gland',
    'root:Host-associated:Birds:Circulatory system',
    'root:Host-associated:Birds:Digestive system',
    'root:Host-associated:Birds:Reproductive system',
    'root:Host-associated:Birds:Respiratory system',
    'root:Host-associated:Fish:Circulatory system',
    'root:Host-associated:Fish:Digestive system',
    'root:Host-associated:Fish:Excretory system',
    'root:Host-associated:Fish:Reproductive system',
    'root:Host-associated:Fish:Skin',
    'root:Host-associated:Human:Circulatory system',
    'root:Host-associated:Human:Digestive system',
    'root:Host-associated:Human:Excretory system',
    'root:Host-associated:Human:Fossil',
    'root:Host-associated:Human:Lympathic system',
    'root:Host-associated:Human:Milk',
    'root:Host-associated:Human:Nervous system',
    'root:Host-associated:Human:Reproductive system',
    'root:Host-associated:Human:Respiratory system',
    'root:Host-associated:Human:Skin',
    'root:Host-associated:Insecta:Digestive system',
    'root:Host-associated:Invertebrates:Bryozoans',
    'root:Host-associated:Invertebrates:Cnidaria',
    'root:Host-associated:Invertebrates:Echinodermata',
    'root:Host-associated:Mammals:Circulatory system',
    'root:Host-associated:Mammals:Digestive system',
    'root:Host-associated:Mammals:Excretory system',
    'root:Host-associated:Mammals:Gastrointestinal tract',
    'root:Host-associated:Mammals:Lymphatic',
    'root:Host-associated:Mammals:Milk',
    'root:Host-associated:Mammals:Nervous system',
    'root:Host-associated:Mammals:Reproductive system',
    'root:Host-associated:Mammals:Respiratory system',
    'root:Host-associated:Mammals:Skin',
    'root:Host-associated:Microbial:Bacteria',
    'root:Host-associated:Microbial:Dinoflagellates',
    'root:Host-associated:Mollusca:Digestive system',
    'root:Host-associated:Mollusca:Respiratory system',
    'root:Host-associated:Mollusca:Shell',
    'root:Host-associated:Plants:Phylloplane',
    'root:Host-associated:Plants:Rhizome',
    'root:Host-associated:Plants:Rhizoplane',
    'root:Host-associated:Plants:Rhizosphere',
    'root:Host-associated:Plants:Root',
    'root:Host-associated:Reptile:Oral cavity',
    'root:Host-associated:Tunicates:Ascidians',
}

# %% ../nbs/01.2_deep_pred.ipynb 39
""" PARAMS
"""
k =100
min_projects_vote=3  # minimum of projects votes for consideration

dominance_thres=0.5#67 # biomes with at least this fraction in the top k will be considered
k2=33
dominance_thres2=0.5 # biomes with at least this fraction in the top k will be considered

# %% ../nbs/01.2_deep_pred.ipynb 42
core_df_file = f"{DATA_DIR}/core_df.tsv"
genus_plus_sp_vec_file = f"{TMP_DIR}/genus_plus_sp_vec.npy"
genus_vec_file = f"{TMP_DIR}/genus_vec.npy"

# %% ../nbs/01.2_deep_pred.ipynb 44
def load_core_data():
    core_df = pd.read_csv(core_df_file,sep='\t')
    genus_plus_sp_vec = np.load(genus_plus_sp_vec_file)
    genus_vec = np.load(genus_vec_file)
    return core_df,genus_vec,genus_plus_sp_vec
    # return core_df,genus_vec

# %% ../nbs/01.2_deep_pred.ipynb 45
core_df,genus_vec,genus_plus_sp_vec = load_core_data()
# core_df,genus_vec = load_core_data()

# %% ../nbs/01.2_deep_pred.ipynb 73
from .goldOntologyAmendments import biome_herarchy_dct

# %% ../nbs/01.2_deep_pred.ipynb 100
# set_piority_terms = ({xx for x in core_df[~core_df.min_annots_amended.isna()].min_annots_amended.unique() for xx in x.split(":")[-2:]}-{'Environmental','Host-associated','Gastrointestinal tract'})|{'Agricultural', 'Agricultural field', 'Amphibia', 'Asphalt lakes', 'Boreal forest', 'Bryozoans', 'Clay', 'Contaminated', 'Crop', 'Desert', 'Forest soil', 'Fossil', 'Grasslands', 'Loam', 'Lymph nodes', 'Milk', 'Mine', 'Mine drainage', 'Nasopharyngeal', 'Nervous system', 'Oil-contaminated', 'Permafrost', 'Pulmonary system', 'Rhizome', 'Rock-dwelling', 'Sand', 'Shrubland', 'Silt', 'Tar', 'Tropical rainforest', 'Tunicates', 'Uranium contaminated', 'Urethra', 'Vagina', 'Wetlands'}

# %% ../nbs/01.2_deep_pred.ipynb 104
tags_dct_file =f"{DATA_DIR}/tags_dct_file.json"

# %% ../nbs/01.2_deep_pred.ipynb 106
with open(tags_dct_file) as h:
    tags_dct = json.load(h)

# %% ../nbs/01.2_deep_pred.ipynb 107
tags_li = list(tags_dct)
# tags_li = [f"{x}|Soil|Terrestrial|Rhizosphere" if len({'Plants','Root','Rhizosphere','Rhizoplane'}&set(x.split("|")))>1 else f"{x}|Non-Defined" if 'Animal' in x else x for x in tags_li ]

# %% ../nbs/01.2_deep_pred.ipynb 110
from itertools import combinations

# %% ../nbs/01.2_deep_pred.ipynb 111
def generate_all_combinations(s):
    """ Generate all combinations of a set """
    result = []
    for r in range(len(s) + 1):
        result.extend(combinations(s, r))
    return result

# %% ../nbs/01.2_deep_pred.ipynb 112
bioms = {x:((set(x.split(":"))),len(x.split(":"))) for x in biome_herarchy_dct.values()}
tag_biomes = {}
for _prediction in tags_li:
    _n_pots = set(_prediction.split("|"))
    for comb in generate_all_combinations(_n_pots):
        comb=set(comb)
        
        sels = [(k,size) for k,(se,size) in bioms.items() if len(comb)==len(comb&se)]
        if len(sels)==0:
            _comb = comb - set("Soil|Terrestrial|Non-Defined".split("|"))
            sels = [(k,size) for k,(se,size) in bioms.items() if len(_comb)==len(_comb&se)]
            if len(sels)==0:
                _comb = _comb - set("Rhizosphere".split("|"))
                sels = [(k,size) for k,(se,size) in bioms.items() if len(_comb)==len(_comb&se)]
        sel = sorted(sels,key=lambda x:x[1])[0][0]
        
        tag_biomes["|".join(sorted(comb))] = sel

# %% ../nbs/01.2_deep_pred.ipynb 117
tnp_core_df_file = f"{DATA_DIR}/core_df_file_2.tsv"

# %% ../nbs/01.2_deep_pred.ipynb 119
slim_core_df = pd.read_csv(tnp_core_df_file,sep='\t')

# %% ../nbs/01.2_deep_pred.ipynb 132
# def pc_deviation_consensus(pr,three = 0.66):
def pc_deviation_consensus(pr,three = 1.000):
    asp = np.argsort(pr)
    topp = pr[asp[-1]]
    _dct = {tags_li[ix]:pr[ix] for ix in asp if pr[ix]/topp >=three}
    _dct.update({tags_li[asp[-1]]:pr[asp[-1]]})
    lins = list(_dct)
    consensus = set(lins[0].split("|"))
    for lin in lins:
        consensus &= set(lin.split("|"))

    _c = "|".join(sorted(consensus))
    res=tag_biomes[_c]
    # return res,_c
    return res,sum(_dct.values())

# %% ../nbs/01.2_deep_pred.ipynb 138
final_model_file = f"{DATA_DIR}/softmax_model.keras"
# final_model_file = f"{DATA_DIR}/softmax_model_DROP_TEST.keras"
final_model_file

# %% ../nbs/01.2_deep_pred.ipynb 140
def focal_loss_fixed(y_true, y_pred):
    # Your implementation of the focal loss
    pass

# Load the model, including the custom loss function
bnn_model2gg = tf.keras.models.load_model(
    final_model_file,
    custom_objects={'focal_loss_fixed': focal_loss_fixed}
)

# %% ../nbs/01.2_deep_pred.ipynb 141
bioms = {x:((set(x.split(":"))),len(x.split(":"))) for x in biome_herarchy_dct.values()}

def find_best_path(_prediction):
    _n_pots = set(_prediction.split("|"))
    sels = [(k,size) for k,(se,size) in bioms.items() if len(_n_pots)==len(_n_pots&se)]
    sel = sorted(sels,key=lambda x:x[1])[0][0]
    return sel

# %% ../nbs/01.2_deep_pred.ipynb 142
# def from_probs_to_pred(_probs):
#     result = []
#     for ix,_ in enumerate(_probs):
#         pr = _probs[ix]
#         if np.isnan(pr).any()==True:
#             du = (None,0.)
#         else:
#             du = pc_deviation_consensus(pr)
#         result.append(du)

#     return result

# %% ../nbs/01.2_deep_pred.ipynb 143
def from_probs_to_pred(_probs,potential_space=None):
    """ predict biome, but in a prefilter potential space. FOR MIXED PREDICTION
    """
    result = []
    if potential_space==None:
        potential_space = [[] for _ in _probs]
    for pr,_pot_space in zip(_probs,potential_space):
        if np.isnan(pr).any()==True:
            du = (None,0.)
        else:
            if len(_pot_space)==0:
                du = pc_deviation_consensus(pr)
            else:
                potential_tags = {k for k,v in tag_biomes.items() if re.search("|".join(_pot_space),v)}
                if len(potential_tags)==0:
                    du = ("|".join(_pot_space),0.)
                else:
                    non_useful_tags = [ix for ix,x in enumerate(tags_li) if x not in potential_tags]
                    _pr = pr.copy()
                    _pr[non_useful_tags] = 0
                    du = pc_deviation_consensus(_pr)
        result.append(du)

    return result

# %% ../nbs/01.2_deep_pred.ipynb 146
def get_lineage_frquencies(co):
    """ Calculate fuzzy array for each sample
    The idea is that each node in the BIOME_AMEND space is a fuzzy category that can be calculated via the frequency of the node in the lineage of the KNN samples:
    """
    """ Function to calculate the requency of each node in the lineages of the knn samples
    """
    total_samples = co.sum()
    _node_frquencies = {}
    for lineage,count in co.items():
        spl = lineage.split(':')
        for ix in range(1,len(spl)+1):
            node = ":".join(spl[:ix])
            _node_frquencies.setdefault(node,[]).append(count)
    node_frequencies = {k:sum(v)/total_samples for k,v in _node_frquencies.items()}
    return node_frequencies

# %% ../nbs/01.2_deep_pred.ipynb 147
# def refine_predictions_knn(prediction,query_vector,full_subject_df,tru_column = 'BIOME_AMEND',k=10,vector_space='g'):
def refine_predictions_knn(prediction,query_vector,full_subject_df,tru_column = 'nu_annot',k=10,vector_space='g'):
    """ Function that given a previous prediction from the deepL model, finds close relatives
    """
    if prediction==None:
        prediction=''
    _subject_df = full_subject_df[full_subject_df[tru_column].str.contains(prediction)]
    subject_vector = genus_vec[_subject_df.index] if vector_space=='g' else genus_plus_sp_vec[_subject_df.index]
    sims = cosine_similarity_pairwise(query_vector,subject_vector)
    sims[np.isnan(sims)] = 0
    argsort_sims = np.argsort(sims)
    
    result =  []
    
    for ix,ass in enumerate(argsort_sims):
        
        _co = _subject_df.iloc[ass[-k:]][tru_column].value_counts()
        _co.index = [x.replace(prediction,'') for x in _co.index]
        _node_freqs = get_lineage_frquencies(_co)
        _filtered = [(k,len(k.split(":"))) for k,v in _node_freqs.items() if v>0.5 and k!='']
        
        _so = sorted(_filtered,key=lambda x:x[1],reverse=True)
        result.append("{}{}".format(prediction,"" if len(_so)==0 else f"{_so[0][0]}"))
    return result

# %% ../nbs/01.2_deep_pred.ipynb 173
import sys
import json
import numpy as np
import pandas as pd
from ssfMiscUtilities.generic import split_list
from .utils import cosine_similarity_pairwise
from .baseData import tax_annotations_from_file
import networkx as nx
from .goldOntologyAmendments import biome_graph

# %% ../nbs/01.2_deep_pred.ipynb 174
np.seterr(divide='ignore', invalid='ignore')  # handle bad files == divition by zero error

# %% ../nbs/01.2_deep_pred.ipynb 175
def full_stack_prediction(query_vector,constrain,vector_space='g'):
    """ Function for prediction of biome based on taxonomic compositon
    """
    # prediction baded on deep learning model
    deep_l_probs = bnn_model2gg(query_vector).numpy()

    predicted_lineages = from_probs_to_pred(deep_l_probs,potential_space=constrain)

    pred_df = pd.DataFrame(predicted_lineages,columns = ['lineage_pred','lineage_pred_prob'])

    # refinement phase
    refined = [None for _ in pred_df.index]

    for pred,gr in pred_df.groupby('lineage_pred'):
        query_array = query_vector[gr.index]
        refs = refine_predictions_knn(pred,query_array,slim_core_df,vector_space=vector_space)
        for ix,pp in zip(gr.index,refs):
            refined[ix] = pp
    pred_df['refined_prediction'] = refined

    for ix,t in enumerate(tags_li):
        pred_df[t] = deep_l_probs[:,ix]

    return pred_df

# %% ../nbs/01.2_deep_pred.ipynb 176
def chunked_fuzzy_prediction(query_vector,constrain,chunk_size=200,vector_space='g'):
    """ wrapper to process prediction in chunks
    """

    N_CHUNKS = int(math.ceil(query_vector.shape[0]/chunk_size))

    splits = split_list(list(range(query_vector.shape[0])),N_CHUNKS)

    results = []

    for spl in tqdm(splits,desc=TAG):
        _results = full_stack_prediction(query_vector[spl],[constrain[ix] for ix in spl],vector_space=vector_space)
        results.append(_results)
    return pd.concat(results).reset_index()
        

# %% ../nbs/01.2_deep_pred.ipynb 177
def vectorise_run(list_of_tax_files,vector_space='g'):
    """ function to predicrize a run based on multiple taxonomy files. e.g. diamond +LSU+SSU, or SSU+LSU
    """
    taxo_sets = {f:tax_annotations_from_file(f) for f in list_of_tax_files}
    tax_tags = {'sp':set(),'gr':set()}
    for f,taxos in taxo_sets.items():
        sp,gr = extract_taxo(taxos,f)
        tax_tags['sp'].update(sp)
        tax_tags['gr'].update(gr)

    if vector_space=='g':
        vec = sentence_vectorization(tax_tags['gr'])
    else:
        vec= calculate_gr_plus_sp_vec(tax_tags['sp'],tax_tags['gr'])
    return vec

# %% ../nbs/01.2_deep_pred.ipynb 178
def predict_runs(
    list_of_list, # list where each element represents a run, with multiple files from taxonomy annotation
    vector_space='g', # debugging option, get prediction for each class
    return_full_preds=False, # debugging option, get prediction for each class
    constrain=None, # debugging option, get prediction for each class
                ):
    """ function to predict lineage of runs, based on multiple taxonomy files. e.g. diamond +LSU+SSU, or SSU+LSU. TAKE FILE WITH TXT FORMAT e.g DRR244685_MERGED_FASTQ_SSU.fasta.mseq.txt
    """
    _vec_size = vec_size*(1 if vector_space=='g' else 2)
    
    full_vec= np.zeros((len(list_of_list),_vec_size))

    if constrain==None:
        constrain = [[] for _ in list_of_list]

    for ix,li in enumerate(list_of_list):
        full_vec[ix] = vectorise_run(li,vector_space=vector_space)

    result = chunked_fuzzy_prediction(full_vec,constrain,vector_space=vector_space)
    
    if return_full_preds==False:
        result = result[["refined_prediction","lineage_pred_prob"]]
    return result

